{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca73ab1",
   "metadata": {},
   "source": [
    "# Susceptibility & Resiliency — Starter Notebook\n",
    "\n",
    "This notebook is a guided, step-by-step starting point for computing **susceptibility** and **resiliency** maps using raster inputs (DEM, slope, soil, drainage distance, landuse, population/building density).\n",
    "\n",
    "Follow the cells in order. Each code cell includes comments explaining what it does.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f1b2b5",
   "metadata": {},
   "source": [
    "## 1) Install required libraries (run once)\n",
    "\n",
    "If you are using a conda environment or pip, install these packages. In Colab you can run `!pip install rasterio numpy matplotlib geopandas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4b918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip installation step if packages are already installed.\n"
     ]
    }
   ],
   "source": [
    "# Install packages if needed (uncomment and run if required)\n",
    "# !pip install rasterio numpy matplotlib geopandas rasterio[all] scikit-image\n",
    "\n",
    "print('Skip installation step if packages are already installed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24616634",
   "metadata": {},
   "source": [
    "## 2) Imports and helper functions\n",
    "\n",
    "We'll write small helper functions to load rasters, normalize them, and perform the weighted overlay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b7398e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_raster(path):\n",
    "    ds = rasterio.open(path)\n",
    "    arr = ds.read(1).astype('float32')\n",
    "    arr[arr == ds.nodata] = np.nan\n",
    "    return arr, ds.profile\n",
    "\n",
    "def save_raster(arr, profile, out_path, nodata_value=-9999):\n",
    "    profile2 = profile.copy()\n",
    "    profile2.update(dtype=rasterio.float32, count=1, compress='lzw', nodata=nodata_value)\n",
    "    arr2 = np.where(np.isnan(arr), nodata_value, arr).astype(rasterio.float32)\n",
    "    with rasterio.open(out_path, 'w', **profile2) as dst:\n",
    "        dst.write(arr2, 1)\n",
    "    print('Saved', out_path)\n",
    "\n",
    "def normalize(arr, method='minmax'):\n",
    "    # arr may contain nan\n",
    "    a = np.array(arr, dtype='float32')\n",
    "    m = np.nanmin(a)\n",
    "    M = np.nanmax(a)\n",
    "    if np.isnan(m) or np.isnan(M) or M == m:\n",
    "        return np.full_like(a, np.nan)\n",
    "    return (a - m) / (M - m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d33f4",
   "metadata": {},
   "source": [
    "## 3) Example: compute susceptibility (weighted overlay)\n",
    "\n",
    "Set paths to your raster layers and define weights. We normalize each raster (0-1) and combine with weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd7499a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /mnt/data/dem.tif not found. Skipping dem.\n",
      "Warning: /mnt/data/slope.tif not found. Skipping slope.\n",
      "Warning: /mnt/data/soil.tif not found. Skipping soil.\n",
      "Warning: /mnt/data/dist_drain.tif not found. Skipping dist_drain.\n",
      "Warning: /mnt/data/landuse.tif not found. Skipping landuse.\n",
      "Computed susceptibility map (shape): None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === USER: set file paths here ===\n",
    "# Replace these with your actual raster file paths (GeoTIFFs)\n",
    "dem_fp = '/mnt/data/dem.tif'             # elevation (higher = less susceptible)\n",
    "slope_fp = '/mnt/data/slope.tif'         # slope (higher slope = less susceptible in flood pooling)\n",
    "soil_fp = '/mnt/data/soil.tif'           # soil permeability index (higher = less susceptible)\n",
    "dist_drain_fp = '/mnt/data/dist_drain.tif' # distance to drainage (higher = less susceptible)\n",
    "landuse_fp = '/mnt/data/landuse.tif'     # categorical; you'll need reclassification to susceptibility index\n",
    "\n",
    "# Example weights (sum to 1.0)\n",
    "sus_weights = {\n",
    "    'dem': 0.30,\n",
    "    'slope': 0.20,\n",
    "    'soil': 0.20,\n",
    "    'dist_drain': 0.15,\n",
    "    'landuse': 0.15\n",
    "}\n",
    "\n",
    "def weighted_overlay_sus(paths, weights):\n",
    "    arrays = {}\n",
    "    profiles = {}\n",
    "    for k, p in paths.items():\n",
    "        if not os.path.exists(p):\n",
    "            print(f'Warning: {p} not found. Skipping {k}.')\n",
    "            arrays[k] = None\n",
    "            profiles[k] = None\n",
    "            continue\n",
    "        arr, prof = load_raster(p)\n",
    "        arrays[k] = arr\n",
    "        profiles[k] = prof\n",
    "    # Simple normalization and combination\n",
    "    score = None\n",
    "    for k, w in weights.items():\n",
    "        arr = arrays.get(k)\n",
    "        if arr is None:\n",
    "            continue\n",
    "        arr_n = normalize(arr)\n",
    "        # For factors where higher value means less susceptibility, invert:\n",
    "        if k in ('dem', 'slope', 'soil', 'dist_drain'):\n",
    "            arr_n = 1 - arr_n  # so low elevation -> high susceptibility\n",
    "        if score is None:\n",
    "            score = np.zeros_like(arr_n, dtype='float32')\n",
    "        score += np.nan_to_num(arr_n) * w\n",
    "    return score, list(profiles.values())[0]\n",
    "\n",
    "paths = {'dem': dem_fp, 'slope': slope_fp, 'soil': soil_fp, 'dist_drain': dist_drain_fp, 'landuse': landuse_fp}\n",
    "sus_map, prof = weighted_overlay_sus(paths, sus_weights)\n",
    "print('Computed susceptibility map (shape):', None if sus_map is None else sus_map.shape)\n",
    "\n",
    "# Save example output (only if computed)\n",
    "if sus_map is not None and prof is not None:\n",
    "    outfp = '/mnt/data/susceptibility.tif'\n",
    "    save_raster(sus_map, prof, outfp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a9061",
   "metadata": {},
   "source": [
    "## 4) Example: compute resiliency\n",
    "\n",
    "Same idea but different weights and interpretation. Higher resiliency = better recovery (we'll produce resiliency score 0-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83069e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: /mnt/data/building_density.tif not found. Skipping building.\n",
      "Warning: /mnt/data/pop_density.tif not found. Skipping population.\n",
      "Warning: /mnt/data/road_access.tif not found. Skipping road_access.\n",
      "Warning: /mnt/data/dem.tif not found. Skipping elevation.\n",
      "Warning: /mnt/data/drainage_eff.tif not found. Skipping drainage_eff.\n",
      "Computed resiliency map (shape): None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === USER: set resiliency raster paths ===\n",
    "building_fp = '/mnt/data/building_density.tif'\n",
    "population_fp = '/mnt/data/pop_density.tif'\n",
    "road_access_fp = '/mnt/data/road_access.tif'  # e.g., distance to nearest primary road (lower = better access)\n",
    "drainage_eff_fp = '/mnt/data/drainage_eff.tif' # drainage efficiency index (higher = better)\n",
    "\n",
    "res_weights = {\n",
    "    'building': 0.25,\n",
    "    'population': 0.20,\n",
    "    'road_access': 0.20,\n",
    "    'elevation': 0.15,\n",
    "    'drainage_eff': 0.20\n",
    "}\n",
    "\n",
    "def weighted_overlay_res(paths, weights):\n",
    "    arrays = {}\n",
    "    profiles = {}\n",
    "    for k, p in paths.items():\n",
    "        if not os.path.exists(p):\n",
    "            print(f'Warning: {p} not found. Skipping {k}.')\n",
    "            arrays[k] = None\n",
    "            profiles[k] = None\n",
    "            continue\n",
    "        arr, prof = load_raster(p)\n",
    "        arrays[k] = arr\n",
    "        profiles[k] = prof\n",
    "    score = None\n",
    "    for k, w in weights.items():\n",
    "        arr = arrays.get(k)\n",
    "        if arr is None:\n",
    "            continue\n",
    "        arr_n = normalize(arr)\n",
    "        # For resiliency factors where higher is better (drainage_eff), keep as is.\n",
    "        # For factors where higher raw value means worse resilience (population, building density, road distance),\n",
    "        # invert so that higher normalized = more resilient\n",
    "        if k in ('building', 'population', 'road_access'):\n",
    "            arr_n = 1 - arr_n\n",
    "        if score is None:\n",
    "            score = np.zeros_like(arr_n, dtype='float32')\n",
    "        score += np.nan_to_num(arr_n) * w\n",
    "    return score, list(profiles.values())[0]\n",
    "\n",
    "paths_res = {'building': building_fp, 'population': population_fp, 'road_access': road_access_fp, 'elevation': dem_fp, 'drainage_eff': drainage_eff_fp}\n",
    "res_map, prof2 = weighted_overlay_res(paths_res, res_weights)\n",
    "print('Computed resiliency map (shape):', None if res_map is None else res_map.shape)\n",
    "\n",
    "if res_map is not None and prof2 is not None:\n",
    "    outfp2 = '/mnt/data/resiliency.tif'\n",
    "    save_raster(res_map, prof2, outfp2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392afd8",
   "metadata": {},
   "source": [
    "## 5) Visualize results\n",
    "\n",
    "A simple plot to inspect the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e48cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def quick_plot(arr, title=''):\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.imshow(arr, interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if sus_map is not None:\n",
    "    quick_plot(sus_map, 'Susceptibility score (0 low - 1 high)')\n",
    "if res_map is not None:\n",
    "    quick_plot(res_map, 'Resiliency score (0 low - 1 high)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb67b81",
   "metadata": {},
   "source": [
    "## 6) Save or export configuration (JSON)\n",
    "\n",
    "Save the weights you used so the web frontend/backend can read them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbb1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# config = {\n",
    "#     \"susceptibility\": sus_weights,\n",
    "#     \"resiliency\": res_weights,\n",
    "#     \"notes\": \"Weights sum to 1. Modify according to expert judgment or calibration.\"\n",
    "# }\n",
    "# with open('/mnt/data/config_weights.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(config, f, indent=2)\n",
    "# print('Saved config to /mnt/data/config_weights.json')\n",
    "# print(json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ed12d",
   "metadata": {},
   "source": [
    "## 7) Next steps and calibration ideas\n",
    "\n",
    "1. Reclassify categorical rasters (landuse, soil) into numeric vulnerability indices before normalization.\n",
    "2. Use expert weighting or analytic hierarchy process (AHP) to set weights instead of guessing.\n",
    "3. Validate results with historical flood extents (if available).\n",
    "4. Consider sensitivity analysis: vary weights and measure change in high-risk areas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7823e",
   "metadata": {},
   "source": [
    "# Dump\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eb5c70",
   "metadata": {},
   "source": [
    "# Susceptibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import rasterio\n",
    "# from rasterio.warp import reproject, Resampling\n",
    "\n",
    "# # Base directory \n",
    "# base_dir = r'C:\\4TH YEAR\\TERM 1\\THS-ST2\\Configuration'\n",
    "\n",
    "# # Subfolders \n",
    "# folders = ['building_footprint', 'dem', 'drainage', 'flood_maps']\n",
    "\n",
    "# # Helper functions \n",
    "# def find_raster_in_folder(folder_path):\n",
    "#     \"\"\"Find the first raster file (.tif, .tiff, .img) in a folder.\"\"\"\n",
    "#     if not os.path.exists(folder_path):\n",
    "#         print(f\"Folder not found: {folder_path}\")\n",
    "#         return None\n",
    "#     for f in os.listdir(folder_path):\n",
    "#         if f.lower().endswith(('.tif', '.tiff', '.img')):\n",
    "#             return os.path.join(folder_path, f)\n",
    "#     print(f\"No raster found in: {folder_path}\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "# def load_raster(fp):\n",
    "#     \"\"\"Load raster as array and profile.\"\"\"\n",
    "#     with rasterio.open(fp) as src:\n",
    "#         return src.read(1).astype('float32'), src.profile\n",
    "\n",
    "\n",
    "# def normalize(arr):\n",
    "#     \"\"\"Normalize array to 0–1 scale.\"\"\"\n",
    "#     arr_min, arr_max = np.nanmin(arr), np.nanmax(arr)\n",
    "#     if arr_max - arr_min == 0:\n",
    "#         return np.zeros_like(arr)\n",
    "#     return (arr - arr_min) / (arr_max - arr_min)\n",
    "\n",
    "\n",
    "# def match_raster(ref_arr, ref_profile, arr, arr_profile):\n",
    "#     \"\"\"Resample arr to match the resolution, CRS, and transform of reference raster.\"\"\"\n",
    "#     dst = np.empty_like(ref_arr, dtype='float32')\n",
    "#     reproject(\n",
    "#         source=arr,\n",
    "#         destination=dst,\n",
    "#         src_transform=arr_profile['transform'],\n",
    "#         src_crs=arr_profile['crs'],\n",
    "#         dst_transform=ref_profile['transform'],\n",
    "#         dst_crs=ref_profile['crs'],\n",
    "#         resampling=Resampling.bilinear\n",
    "#     )\n",
    "#     return dst\n",
    "\n",
    "\n",
    "# def save_raster(array, profile, output_path):\n",
    "#     \"\"\"Save array as GeoTIFF.\"\"\"\n",
    "#     profile.update(dtype=rasterio.float32, count=1)\n",
    "#     with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "#         dst.write(array.astype(rasterio.float32), 1)\n",
    "\n",
    "\n",
    "# # Automatically locate raster files \n",
    "# paths = {}\n",
    "# for f in folders:\n",
    "#     folder_path = os.path.join(base_dir, f)\n",
    "#     raster_fp = find_raster_in_folder(folder_path)\n",
    "#     if raster_fp:\n",
    "#         paths[f] = raster_fp\n",
    "#         print(f\"Found raster for {f}: {raster_fp}\")\n",
    "#     else:\n",
    "#         print(f\"Skipping {f} (no file found).\")\n",
    "\n",
    "# if not paths:\n",
    "#     raise FileNotFoundError(\"No raster files found. Please check your folder paths.\")\n",
    "\n",
    "# # Weights (must sum to 1.0)\n",
    "# sus_weights = {\n",
    "#     'dem': 0.4,\n",
    "#     'drainage': 0.3,\n",
    "#     'flood_maps': 0.2,\n",
    "#     'building_footprint': 0.1\n",
    "# }\n",
    "\n",
    "\n",
    "# # Weighted overlay computation \n",
    "# def weighted_overlay_sus(paths, weights):\n",
    "#     arrays, profiles = {}, {}\n",
    "\n",
    "#     # Load all rasters\n",
    "#     for k, p in paths.items():\n",
    "#         arr, prof = load_raster(p)\n",
    "#         arrays[k] = arr\n",
    "#         profiles[k] = prof\n",
    "\n",
    "#     # Pick the first raster as reference\n",
    "#     ref_key = next(iter(arrays))\n",
    "#     ref_arr = arrays[ref_key]\n",
    "#     ref_prof = profiles[ref_key]\n",
    "\n",
    "#     score = np.zeros_like(ref_arr, dtype='float32')\n",
    "\n",
    "#     # Combine layers using weights\n",
    "#     for k, w in weights.items():\n",
    "#         arr = arrays.get(k)\n",
    "#         prof = profiles.get(k)\n",
    "#         if arr is None or prof is None:\n",
    "#             continue\n",
    "#         # Resample to match reference raster\n",
    "#         arr_resampled = match_raster(ref_arr, ref_prof, arr, prof)\n",
    "#         arr_n = normalize(arr_resampled)\n",
    "\n",
    "#         # Invert if higher value = less susceptible\n",
    "#         if k in ('dem', 'drainage'):\n",
    "#             arr_n = 1 - arr_n\n",
    "\n",
    "#         score += np.nan_to_num(arr_n) * w\n",
    "\n",
    "#     return score, ref_prof\n",
    "\n",
    "\n",
    "# # Run computation \n",
    "# sus_map, prof = weighted_overlay_sus(paths, sus_weights)\n",
    "# print(\"Computed susceptibility map with shape:\", sus_map.shape)\n",
    "\n",
    "# # Save output \n",
    "# output_fp = os.path.join(base_dir, \"susceptibility_map.tif\")\n",
    "# save_raster(sus_map, prof, output_fp)\n",
    "# print(f\"Saved susceptibility map to: {output_fp}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3140056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Susceptibility Configuration - Complete & Verified ===\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- 1️⃣ Base directory & folders ----\n",
    "base_dir = r'C:\\4TH YEAR\\TERM 1\\THS-ST2\\Configuration'\n",
    "folders = ['building_footprint', 'dem', 'drainage', 'flood_maps']\n",
    "\n",
    "# ---- 2️⃣ Helper functions ----\n",
    "def find_raster_in_folder(folder_path):\n",
    "    \"\"\"Find the first raster file (.tif, .tiff, .img) in a folder.\"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"⚠️ Folder not found: {folder_path}\")\n",
    "        return None\n",
    "    for f in os.listdir(folder_path):\n",
    "        if f.lower().endswith(('.tif', '.tiff', '.img')):\n",
    "            return os.path.join(folder_path, f)\n",
    "    print(f\"⚠️ No raster found in: {folder_path}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_raster(fp):\n",
    "    \"\"\"Load raster as array and profile.\"\"\"\n",
    "    with rasterio.open(fp) as src:\n",
    "        return src.read(1).astype('float32'), src.profile\n",
    "\n",
    "\n",
    "def normalize(arr):\n",
    "    \"\"\"Normalize array to 0–1 scale.\"\"\"\n",
    "    arr_min, arr_max = np.nanmin(arr), np.nanmax(arr)\n",
    "    if arr_max - arr_min == 0:\n",
    "        return np.zeros_like(arr)\n",
    "    return (arr - arr_min) / (arr_max - arr_min)\n",
    "\n",
    "\n",
    "def match_raster(ref_arr, ref_profile, arr, arr_profile):\n",
    "    \"\"\"Resample arr to match the resolution, CRS, and transform of reference raster.\"\"\"\n",
    "    dst = np.empty_like(ref_arr, dtype='float32')\n",
    "    reproject(\n",
    "        source=arr,\n",
    "        destination=dst,\n",
    "        src_transform=arr_profile['transform'],\n",
    "        src_crs=arr_profile['crs'],\n",
    "        dst_transform=ref_profile['transform'],\n",
    "        dst_crs=ref_profile['crs'],\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "    return dst\n",
    "\n",
    "\n",
    "def save_raster(array, profile, output_path):\n",
    "    \"\"\"Save array as GeoTIFF.\"\"\"\n",
    "    profile.update(dtype=rasterio.float32, count=1)\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(array.astype(rasterio.float32), 1)\n",
    "\n",
    "\n",
    "# ---- 3️⃣ Automatically locate raster files ----\n",
    "paths = {}\n",
    "for f in folders:\n",
    "    folder_path = os.path.join(base_dir, f)\n",
    "    raster_fp = find_raster_in_folder(folder_path)\n",
    "    if raster_fp:\n",
    "        paths[f] = raster_fp\n",
    "        print(f\"✅ Found raster for {f}: {raster_fp}\")\n",
    "    else:\n",
    "        print(f\"❌ Skipping {f} (no file found).\")\n",
    "\n",
    "if not paths:\n",
    "    raise FileNotFoundError(\"No raster files found. Please check your folder paths.\")\n",
    "\n",
    "\n",
    "# ---- 4️⃣ Define weights (sum to 1.0) ----\n",
    "sus_weights = {\n",
    "    'dem': 0.4,\n",
    "    'drainage': 0.3,\n",
    "    'flood_maps': 0.2,\n",
    "    'building_footprint': 0.1\n",
    "}\n",
    "\n",
    "assert abs(sum(sus_weights.values()) - 1.0) < 1e-6, \"❌ Weights must sum to 1.0\"\n",
    "print(\"✅ Weights verified (sum = 1.0)\")\n",
    "\n",
    "\n",
    "# ---- 5️⃣ Print CRS and shapes before alignment ----\n",
    "print(\"\\n🔍 Checking raster CRS and shapes:\")\n",
    "for name, p in paths.items():\n",
    "    with rasterio.open(p) as src:\n",
    "        print(f\"{name:20s} | CRS: {src.crs} | Shape: {src.read(1).shape}\")\n",
    "\n",
    "\n",
    "# ---- 6️⃣ Weighted overlay computation ----\n",
    "def weighted_overlay_sus(paths, weights):\n",
    "    arrays, profiles = {}, {}\n",
    "\n",
    "    # Load all rasters\n",
    "    for k, p in paths.items():\n",
    "        arr, prof = load_raster(p)\n",
    "        arrays[k] = arr\n",
    "        profiles[k] = prof\n",
    "\n",
    "    # Use DEM as reference\n",
    "    ref_key = 'dem' if 'dem' in arrays else next(iter(arrays))\n",
    "    ref_arr = arrays[ref_key]\n",
    "    ref_prof = profiles[ref_key]\n",
    "    print(f\"\\n🗺️ Using {ref_key.upper()} as reference raster for alignment.\")\n",
    "\n",
    "    score = np.zeros_like(ref_arr, dtype='float32')\n",
    "\n",
    "    # Combine layers using weights\n",
    "    for k, w in weights.items():\n",
    "        arr = arrays.get(k)\n",
    "        prof = profiles.get(k)\n",
    "        if arr is None or prof is None:\n",
    "            print(f\"⚠️ Skipping {k}: missing data\")\n",
    "            continue\n",
    "        # Resample to match reference raster\n",
    "        arr_resampled = match_raster(ref_arr, ref_prof, arr, prof)\n",
    "        arr_n = normalize(arr_resampled)\n",
    "\n",
    "        # Invert if higher value = less susceptible\n",
    "        if k in ('dem', 'drainage'):\n",
    "            arr_n = 1 - arr_n\n",
    "\n",
    "        score += np.nan_to_num(arr_n) * w\n",
    "\n",
    "    return score, ref_prof\n",
    "\n",
    "\n",
    "# ---- 7️⃣ Run computation ----\n",
    "sus_map, prof = weighted_overlay_sus(paths, sus_weights)\n",
    "print(\"\\n✅ Computed susceptibility map with shape:\", sus_map.shape)\n",
    "\n",
    "\n",
    "# ---- 8️⃣ Visualization of normalized layers ----\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, (k, p) in enumerate(paths.items(), 1):\n",
    "    arr, prof = load_raster(p)\n",
    "    arr_res = match_raster(sus_map, prof, arr, prof)\n",
    "    arr_n = normalize(arr_res)\n",
    "    if k in ('dem', 'drainage'):\n",
    "        arr_n = 1 - arr_n\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(arr_n, cmap='viridis')\n",
    "    plt.title(f\"{k} (normalized)\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---- 9️⃣ Visualization of final susceptibility map ----\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(sus_map, cmap='inferno')\n",
    "plt.colorbar(label='Flood Susceptibility Index')\n",
    "plt.title('Final Susceptibility Map')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---- 🔟 Save output ----\n",
    "output_fp = os.path.join(base_dir, \"susceptibility_map.tif\")\n",
    "save_raster(sus_map, prof, output_fp)\n",
    "print(f\"💾 Saved susceptibility map to: {output_fp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf99be",
   "metadata": {},
   "source": [
    "# Resiliency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54581495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION AND FILE LOADING ===\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rasterio.plot import show\n",
    "from skimage import io\n",
    "\n",
    "# === DEFINE FOLDERS ===\n",
    "folders = {\n",
    "    \"building_footprint\": \"building_footprint\",\n",
    "    \"dem\": \"dem\",\n",
    "    \"drainage\": \"drainage\",\n",
    "    \"flood_maps\": \"flood_maps\"\n",
    "}\n",
    "\n",
    "# === AUTOMATIC FILE DISCOVERY ===\n",
    "data_files = {}\n",
    "\n",
    "for name, folder in folders.items():\n",
    "    path = os.path.join(os.getcwd(), folder)\n",
    "    if os.path.exists(path):\n",
    "        files = [os.path.join(path, f) for f in os.listdir(path) if not f.startswith('.')]\n",
    "        data_files[name] = files\n",
    "    else:\n",
    "        print(f\"⚠️ Folder not found: {folder}\")\n",
    "\n",
    "# === DISPLAY FOUND FILES ===\n",
    "print(\"📂 Loaded folders and files:\")\n",
    "for key, files in data_files.items():\n",
    "    print(f\"\\n📁 {key}:\")\n",
    "    for f in files:\n",
    "        print(\"   -\", os.path.basename(f))\n",
    "\n",
    "# === EXAMPLE: LOAD FIRST FILES FROM EACH FOLDER ===\n",
    "print(\"\\n✅ Attempting to load sample files...\\n\")\n",
    "\n",
    "loaded_data = {}\n",
    "\n",
    "for key, files in data_files.items():\n",
    "    if not files:\n",
    "        continue\n",
    "    sample_file = files[0]\n",
    "    print(f\"➡️ Loading {key} sample: {os.path.basename(sample_file)}\")\n",
    "\n",
    "    try:\n",
    "        if sample_file.endswith(('.shp', '.geojson')):\n",
    "            loaded_data[key] = gpd.read_file(sample_file)\n",
    "            print(f\"   🗺️ Loaded vector data with {len(loaded_data[key])} features.\")\n",
    "        elif sample_file.endswith(('.tif', '.tiff')):\n",
    "            loaded_data[key] = rasterio.open(sample_file)\n",
    "            print(f\"   🌄 Loaded raster data ({loaded_data[key].width}x{loaded_data[key].height}).\")\n",
    "        elif sample_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            loaded_data[key] = io.imread(sample_file)\n",
    "            print(f\"   🖼️ Loaded image with shape {loaded_data[key].shape}.\")\n",
    "        else:\n",
    "            print(f\"   ⚠️ Unsupported file format: {sample_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Error loading {sample_file}: {e}\")\n",
    "\n",
    "# === OPTIONAL: QUICK VISUALIZATION ===\n",
    "for key, data in loaded_data.items():\n",
    "    print(f\"\\n🧭 Preview of {key} data:\")\n",
    "    if isinstance(data, gpd.GeoDataFrame):\n",
    "        data.plot(figsize=(6,6))\n",
    "        plt.title(f\"{key} - Vector Preview\")\n",
    "        plt.show()\n",
    "    elif isinstance(data, rasterio.io.DatasetReader):\n",
    "        show(data)\n",
    "        plt.title(f\"{key} - Raster Preview\")\n",
    "        plt.show()\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        plt.imshow(data)\n",
    "        plt.title(f\"{key} - Image Preview\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
